{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nybU39habY14",
        "outputId": "4d3156ca-837e-4113-fdac-7944f848e87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4950 - accuracy: 0.8250\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3757 - accuracy: 0.8656\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3367 - accuracy: 0.8780\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3137 - accuracy: 0.8847\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2968 - accuracy: 0.8904\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3971 - accuracy: 0.8582\n",
            "\n",
            "Test accuracy: 0.8582000136375427\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 input images\n",
        "    layers.Dense(128, activation='relu'),   # Fully connected layer with 128 neurons\n",
        "    layers.Dense(10, activation='softmax')  # Output layer with 10 neurons for 10 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n",
        "#Kegunaan dari codingan di atas adalah:\n",
        "#1. Load Data:\n",
        "#Menggunakan keras.datasets.fashion_mnist.load_data() untuk memuat dataset Fashion MNIST. Dataset ini terdiri dari gambar-gambar pakaian dan label-labelnya.\n",
        "#Data kemudian dipecah menjadi data pelatihan (x_train, y_train) dan data uji (x_test, y_test).\n",
        "\n",
        "#2. Preprocess Data:\n",
        "# Normalisasi data gambar agar nilainya berada dalam rentang 0 hingga 1 dengan membagi setiap nilai piksel dengan 255.0.\n",
        "\n",
        "#3. Build Neural Network Model:\n",
        "# Menggunakan Sequential dari Keras untuk membuat model neural network berurutan.\n",
        "# Layer pertama (Flatten) digunakan untuk meratakan input 28x28 menjadi satu dimensi (784).\n",
        "# Layer kedua (Dense) adalah fully connected layer dengan 128 neuron dan fungsi aktivasi ReLU.\n",
        "# Layer ketiga (Dense) adalah layer output dengan 10 neuron (sesuai dengan jumlah kelas pada Fashion MNIST) dan fungsi aktivasi softmax.\n",
        "\n",
        "#4. Compile Model:\n",
        "# Menggunakan model.compile untuk menentukan konfigurasi pelatihan seperti optimizer, fungsi loss, dan metrik evaluasi (dalam contoh ini, kita menggunakan Adam optimizer dan sparse categorical crossentropy loss).\n",
        "\n",
        "#5. Train Model:\n",
        "# Menggunakan model.fit untuk melatih model dengan data pelatihan (x_train, y_train) selama beberapa epoch (dalam contoh ini, 5 epoch).\n",
        "# Proses ini akan mengoptimalkan parameter model berdasarkan perbedaan antara prediksi dan label yang sebenarnya.\n",
        "\n",
        "#6. Evaluate Model:\n",
        "# Menggunakan model.evaluate untuk mengevaluasi performa model pada data uji (x_test, y_test).\n",
        "# Hasilnya mencakup loss dan akurasi pada dataset uji\n",
        ".\n",
        "#7. Print Test Accuracy:\n",
        "# Mencetak akurasi pengujian pada dataset uji.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOAJL8Plb9F7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}